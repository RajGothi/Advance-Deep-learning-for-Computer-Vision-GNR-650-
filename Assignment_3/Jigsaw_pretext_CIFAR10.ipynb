{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of iterations it took to build top - 1000 permutations array = 1411\n",
      "No of permutations 1000\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "\n",
    "# Build list of all possible permutations\n",
    "random.seed(42)\n",
    "permuts_list = list(itertools.permutations(range(9)))\n",
    "permuts_array = np.array(permuts_list)\n",
    "no_permuts = len(permuts_list)\n",
    "\n",
    "\n",
    "# Take top x permutations which have max average hamming distance\n",
    "permuts_to_take = 1000\n",
    "set_of_taken = set()\n",
    "cnt_iterations = 0\n",
    "while True:\n",
    "    cnt_iterations += 1\n",
    "    x = random.randint(1, no_permuts - 1)\n",
    "    y = random.randint(1, no_permuts - 1)\n",
    "    permut_1 = permuts_array[x]\n",
    "    permut_2 = permuts_array[y]\n",
    "    hd = hamming(permut_1, permut_2)\n",
    "\n",
    "    if hd > 0.9 and (not x in set_of_taken) and (not y in set_of_taken):\n",
    "        set_of_taken.add(x)\n",
    "        set_of_taken.add(y)\n",
    "\n",
    "        if len(set_of_taken) == permuts_to_take:\n",
    "            break\n",
    "        \n",
    "print (\"No of iterations it took to build top - {} permutations array = {}\".format(permuts_to_take, cnt_iterations))\n",
    "print (\"No of permutations\", len(set_of_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the array for selected permutation indices above\n",
    "selected_permuts = []\n",
    "for ind, perm_id in enumerate(set_of_taken):\n",
    "    if ind < 10:\n",
    "        print (\"Sample permutation {}\".format(ind))\n",
    "        print (permuts_array[perm_id])\n",
    "    selected_permuts.append(permuts_array[perm_id])\n",
    "\n",
    "selected_permuts = np.array(selected_permuts)\n",
    "np.save('selected_permuts.npy', selected_permuts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "def_data_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "hflip_data_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "darkness_jitter_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "lightness_jitter_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "rotations_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "all_in_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "def crop_from_center(pil_image, new_h, new_w):\n",
    "\n",
    "    width, height = pil_image.size  # Get dimensions\n",
    "\n",
    "    left = (width - new_w) / 2\n",
    "    top = (height - new_h) / 2\n",
    "    right = (width + new_w) / 2\n",
    "    bottom = (height + new_h) / 2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    pil_image = pil_image.crop((left, top, right, bottom))\n",
    "\n",
    "    return pil_image\n",
    "\n",
    "\n",
    "def get_nine_crops(pil_image):\n",
    "    \"\"\"\n",
    "    Get nine crops for a square pillow image. That is height and width of the image should be same.\n",
    "    :param pil_image: pillow image\n",
    "    :return: List of pillow images. The nine crops\n",
    "    \"\"\"\n",
    "    w, h = pil_image.size\n",
    "    diff = int(w/3)\n",
    "\n",
    "    r_vals = [0, diff, 2 * diff]\n",
    "    c_vals = [0, diff, 2 * diff]\n",
    "\n",
    "    list_patches = []\n",
    "\n",
    "    for r in r_vals:\n",
    "        for c in c_vals:\n",
    "\n",
    "            left = c\n",
    "            top = r\n",
    "            right = c + diff\n",
    "            bottom = r + diff\n",
    "\n",
    "            patch = pil_image.crop((left, top, right, bottom))\n",
    "            list_patches.append(patch)\n",
    "\n",
    "    return list_patches\n",
    "\n",
    "\n",
    "def split_train_into_train_val(train_file_ids, train_file_paths, train_labels, test_size=0.1):\n",
    "    \"\"\"\n",
    "    Split train_file_paths and train_labels to train_file_paths, val_file_paths and\n",
    "    train_labels, val_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a mapping between image_id and file_path\n",
    "    image_id_name_map = dict(zip(train_file_ids, train_file_paths))\n",
    "\n",
    "    # Get validation files and validation labels separate\n",
    "    train_file_ids, val_file_ids, train_labels, val_labels = train_test_split(\n",
    "        train_file_ids, train_labels, test_size=test_size, random_state=5, shuffle=True\n",
    "    )\n",
    "    train_file_paths = [image_id_name_map[image_id] for image_id in train_file_ids]\n",
    "    val_file_paths = [image_id_name_map[image_id] for image_id in val_file_ids]\n",
    "\n",
    "    print (\"Length of train files list\", len(train_file_paths))\n",
    "    print (\"Length of train labels\", len(train_labels))\n",
    "    print (\"Length of val files list\", len(val_file_paths))\n",
    "    print (\"Length of val labels\", len(val_labels))\n",
    "\n",
    "    return train_file_ids, val_file_ids, train_file_paths, val_file_paths, train_labels, val_labels\n",
    "\n",
    "def get_paths():\n",
    "    data_dir = '/home/raj/GNR-650/Assignment_3/CIFAR-10-images/train'\n",
    "    file_paths_to_return = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                file_paths_to_return.append(root+'/'+file)                        \n",
    "    \n",
    "    return file_paths_to_return\n",
    "\n",
    "def get_train_test_file_paths_n_labels():\n",
    "    \"\"\"\n",
    "    Get array train_file_paths, train_labels, test_file_paths and test_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Data loading and data generators set up\n",
    "    #par_data_dir = 'train'\n",
    "    images_data_dir = 'train'\n",
    "    train_test_split_file = 'train_test_split.txt'\n",
    "    images_file = 'images.txt'\n",
    "    labels_file = 'image_class_labels.txt'\n",
    "\n",
    "    # Read the images_file which stores image-id and image-name mapping\n",
    "    image_file_id_df = pd.read_csv(images_file, sep=' ', header=None)\n",
    "    image_file_id_mat = image_file_id_df.values\n",
    "    image_id_name_map = dict(zip(image_file_id_mat[:, 0], image_file_id_mat[:, 1]))\n",
    "\n",
    "    # Read the train_test_split file which stores image-id and train-test split mapping\n",
    "    image_id_train_test_split_df = pd.read_csv(train_test_split_file, sep=' ', header=None)\n",
    "    image_id_train_test_split_mat = image_id_train_test_split_df.values\n",
    "    image_id_train_test_split_map = dict(zip(image_id_train_test_split_mat[:, 0],\n",
    "                                             image_id_train_test_split_mat[:, 1]))\n",
    "\n",
    "    # Read the image class labels file\n",
    "    image_id_label_df = pd.read_csv(labels_file, sep=' ', header=None)\n",
    "    image_id_label_mat = image_id_label_df.values\n",
    "    image_id_label_map = dict(zip(image_id_label_mat[:, 0], image_id_label_mat[:, 1]))\n",
    "\n",
    "    # Put together train_files train_labels test_files and test_labels lists\n",
    "    train_image_ids, test_image_ids = [], []\n",
    "    train_file_paths, test_file_paths = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    for file_id in image_id_name_map.keys():\n",
    "        file_name = image_id_name_map[file_id]\n",
    "        is_train = image_id_train_test_split_map[file_id]\n",
    "        label = image_id_label_map[file_id] - 1  # To ensure labels start from 0\n",
    "\n",
    "        if is_train:\n",
    "            train_image_ids.append(file_id)\n",
    "            train_file_paths.append(os.path.join(images_data_dir, file_name))\n",
    "            train_labels.append(label)\n",
    "        else:\n",
    "            test_image_ids.append(file_id)\n",
    "            test_file_paths.append(os.path.join(images_data_dir, file_name))\n",
    "            test_labels.append(label)\n",
    "\n",
    "    print (\"Length of train files list\", len(train_file_paths))\n",
    "    print (\"Length of train labels list\", len(train_labels))\n",
    "    print (\"Length of test files list\", len(test_file_paths))\n",
    "    print (\"Length of test labels list\", len(test_labels))\n",
    "\n",
    "    return train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Jigsaw from permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#from dataset_helpers import crop_from_center, get_nine_crops\n",
    "\n",
    "\n",
    "class GetDataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        'Initialization'\n",
    "        self.imgs = [(img_path, label) for img_path, label in zip(file_paths, labels)]\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Select sample\n",
    "        file_path = self.file_paths[index]\n",
    "        label = self.labels[index]\n",
    "        pil_image = Image.open(file_path)\n",
    "\n",
    "        # Check if image has only single channel. If True, then swap with 0th image\n",
    "        # Assumption 0th image has got 3 number of channels\n",
    "        if len(pil_image.getbands()) != 3:\n",
    "            file_path = self.file_paths[0]\n",
    "            label = self.labels[0]\n",
    "            pil_image = Image.open(file_path)\n",
    "\n",
    "        # Convert image to torch tensor\n",
    "        tr_image = self.transform(pil_image)\n",
    "\n",
    "        return tr_image, label\n",
    "\n",
    "\n",
    "class GetJigsawPuzzleDataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, file_paths, avail_permuts_file_path, range_permut_indices=None, transform=None):\n",
    "        'Initialization'\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "        self.permuts_avail = np.load(avail_permuts_file_path)\n",
    "        self.range_permut_indices = range_permut_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Select sample\n",
    "        file_path = self.file_paths[index]\n",
    "        pil_image = Image.open(file_path)\n",
    "\n",
    "        # Check if image has only single channel. If True, then swap with 0th image\n",
    "        # Assumption 0th image has got 3 number of channels\n",
    "        if len(pil_image.getbands()) != 3:\n",
    "            file_path = self.file_paths[0]\n",
    "            pil_image = Image.open(file_path)\n",
    "\n",
    "        # Convert image to torch tensor\n",
    "        pil_image = pil_image.resize((128, 128))\n",
    "        pil_image = crop_from_center(pil_image, 105, 105)\n",
    "\n",
    "        # Get nine crops for the image\n",
    "        nine_crops = get_nine_crops(pil_image)\n",
    "\n",
    "        # Permut the 9 patches obtained from the image\n",
    "        if self.range_permut_indices:\n",
    "            permut_ind = random.randint(self.range_permut_indices[0], self.range_permut_indices[1])\n",
    "        else:\n",
    "            permut_ind = random.randint(0, len(self.permuts_avail) - 1)\n",
    "\n",
    "        permutation_config = self.permuts_avail[permut_ind]\n",
    "\n",
    "        permuted_patches_arr = [None] * 9\n",
    "        for crop_new_pos, crop in zip(permutation_config, nine_crops):\n",
    "            permuted_patches_arr[crop_new_pos] = crop\n",
    "\n",
    "        # Apply data transforms\n",
    "        tensor_patches = torch.zeros(9, 3, 32, 32)\n",
    "        for ind, jigsaw_patch in enumerate(permuted_patches_arr):\n",
    "            jigsaw_patch_tr = self.transform(jigsaw_patch)\n",
    "            tensor_patches[ind] = jigsaw_patch_tr\n",
    "\n",
    "        return tensor_patches, permut_ind\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Resnet model\n",
    "Credit: https://github.com/aniket03/self_supervised_bird_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, siamese_deg=9, train_contrastive=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.siamese_deg = siamese_deg\n",
    "        self.train_contrastive = train_contrastive\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "\n",
    "        if self.siamese_deg is None:\n",
    "            self.fc = nn.Linear(2048 * block.expansion, num_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(2048 * block.expansion * self.siamese_deg, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def get_feature_vectors(self, input_batch):\n",
    "        # Each input_batch would be of shape (batch_size, color_channels, h, w)\n",
    "        x = self.conv1(input_batch)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "\n",
    "        # Data returned by data loaders is of the shape (batch_size, no_patches, h_patch, w_patch)\n",
    "        # That's why named input to patches_batch\n",
    "\n",
    "        if self.siamese_deg is None:\n",
    "            final_feat_vectors = self.get_feature_vectors(input_batch)\n",
    "            x = F.dropout(final_feat_vectors)\n",
    "            x = F.log_softmax(self.fc(x))\n",
    "        elif not self.train_contrastive:\n",
    "            final_feat_vectors = None\n",
    "            for patch_ind in range(self.siamese_deg):\n",
    "                # Each patch_batch would be of shape (batch_size, color_channels, h_patch, w_patch)\n",
    "                patch_batch = input_batch[:, patch_ind, :, :, :]\n",
    "                patch_batch_features = self.get_feature_vectors(patch_batch)\n",
    "\n",
    "                if patch_ind == 0:\n",
    "                    final_feat_vectors = patch_batch_features\n",
    "                else:\n",
    "                    final_feat_vectors = torch.cat([final_feat_vectors, patch_batch_features], dim=1)\n",
    "            x = F.dropout(final_feat_vectors)\n",
    "            x = F.log_softmax(self.fc(x))\n",
    "        else:\n",
    "            q_img_batch = input_batch[:, 0, :, :, :]\n",
    "            p_img_batch = input_batch[:, 1, :, :, :]\n",
    "            n_img_batch = input_batch[:, 2, :, :, :]\n",
    "\n",
    "            q_img_batch_feats = self.get_feature_vectors(q_img_batch)\n",
    "            p_img_batch_feats = self.get_feature_vectors(p_img_batch)\n",
    "            n_img_batch_feats = self.get_feature_vectors(n_img_batch)\n",
    "\n",
    "            pos_sq_dist = torch.norm(q_img_batch_feats - p_img_batch_feats, p=2, dim=1) ** 2\n",
    "            neg_sq_dist = torch.norm(q_img_batch_feats - n_img_batch_feats, p=2, dim=1) ** 2\n",
    "\n",
    "            x = pos_sq_dist - neg_sq_dist\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def _resnet(block, layers, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    \"\"\"\n",
    "    return _resnet(BasicBlock, [2, 2, 2, 2], **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "\n",
    "def get_count_correct_preds(network_output, target):\n",
    "\n",
    "    output = network_output\n",
    "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "    pred.data = pred.data.view_as(target.data)\n",
    "    correct = target.eq(pred).sum().item()\n",
    "\n",
    "    return correct\n",
    "\n",
    "\n",
    "class ModelTrainTest():\n",
    "\n",
    "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
    "        super(ModelTrainTest, self).__init__()\n",
    "        self.network = network\n",
    "        self.device = device\n",
    "        self.model_file_path = model_file_path\n",
    "        self.threshold = threshold\n",
    "        self.train_loss = 1e9\n",
    "        self.val_loss = 1e9\n",
    "\n",
    "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
    "        self.network.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        cnt_batches = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = self.network(data)\n",
    "\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            clip_grad_norm_(self.network.parameters(), params_max_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            correct += get_count_correct_preds(output, target)\n",
    "            train_loss += loss.item()\n",
    "            cnt_batches += 1\n",
    "\n",
    "            del data, target, output\n",
    "\n",
    "        train_loss /= cnt_batches\n",
    "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
    "\n",
    "        if val_loss < self.val_loss - self.threshold:\n",
    "            self.val_loss = val_loss\n",
    "            torch.save(self.network.state_dict(), self.model_file_path)\n",
    "\n",
    "        train_acc = correct / len(train_data_loader.dataset)\n",
    "\n",
    "        print('\\nAfter epoch {} - Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            epoch, train_loss, correct, len(train_data_loader.dataset),\n",
    "            100. * correct / len(train_data_loader.dataset)))\n",
    "\n",
    "        return train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "    def test(self, epoch, test_data_loader):\n",
    "        self.network.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_data_loader):\n",
    "            data, target = Variable(data, volatile=True).to(self.device), Variable(target).to(self.device)\n",
    "            output = self.network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
    "\n",
    "            correct += get_count_correct_preds(output, target)\n",
    "\n",
    "            del data, target, output\n",
    "\n",
    "        test_loss /= len(test_data_loader.dataset)\n",
    "        test_acc = correct / len(test_data_loader.dataset)\n",
    "        print('\\nAfter epoch {} - Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            epoch, test_loss, correct, len(test_data_loader.dataset),\n",
    "            100. * correct / len(test_data_loader.dataset)))\n",
    "\n",
    "        return  test_loss, test_acc\n",
    "\n",
    "\n",
    "class JigsawModelTrainTest():\n",
    "\n",
    "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
    "        super(JigsawModelTrainTest, self).__init__()\n",
    "        self.network = network\n",
    "        self.device = device\n",
    "        self.model_file_path = model_file_path\n",
    "        self.threshold = threshold\n",
    "        self.train_loss = 1e9\n",
    "        self.val_loss = 1e9\n",
    "\n",
    "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
    "        self.network.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        cnt_batches = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "\n",
    "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            output = self.network(data)\n",
    "\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(self.network.parameters(), params_max_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            correct += get_count_correct_preds(output, target)\n",
    "            train_loss += loss.item()\n",
    "            cnt_batches += 1\n",
    "\n",
    "            del data, target, output\n",
    "\n",
    "        train_loss /= cnt_batches\n",
    "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
    "\n",
    "        if val_loss < self.val_loss - self.threshold:\n",
    "            self.val_loss = val_loss\n",
    "            torch.save(self.network.state_dict(), self.model_file_path)\n",
    "\n",
    "        train_acc = correct / len(train_data_loader.dataset)\n",
    "\n",
    "        print('\\nAfter epoch {} - Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            epoch, train_loss, correct, len(train_data_loader.dataset),\n",
    "            100. * correct / len(train_data_loader.dataset)))\n",
    "\n",
    "        return train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "    def test(self, epoch, test_data_loader):\n",
    "        self.network.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_data_loader):\n",
    "            data, target = Variable(data, volatile=True).to(self.device), Variable(target).to(self.device)\n",
    "            output = self.network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
    "\n",
    "            correct += get_count_correct_preds(output, target)\n",
    "\n",
    "            del data, target, output\n",
    "\n",
    "        test_loss /= len(test_data_loader.dataset)\n",
    "        test_acc = correct / len(test_data_loader.dataset)\n",
    "        print('\\nAfter epoch {} - Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            epoch, test_loss, correct, len(test_data_loader.dataset),\n",
    "            100. * correct / len(test_data_loader.dataset)))\n",
    "\n",
    "        return  test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfSupervisedModel(\n",
      "  (patch_model): CNNModel(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2): ReLU()\n",
      "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU()\n",
      "    (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
      "    (relu4): ReLU()\n",
      "  )\n",
      "  (fc2): Linear(in_features=4608, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "Total model parameters: 25M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Map to a 1000-dimensional vector\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        # x = self.relu3(self.conv3(x))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "class SelfSupervisedModel(nn.Module):\n",
    "    def __init__(self, siamese_deg,num_outputs):\n",
    "        super(SelfSupervisedModel, self).__init__()\n",
    "        self.siamese_deg = siamese_deg\n",
    "        self.patch_model = CNNModel()\n",
    "        self.fc2 = nn.Linear(9 * 512, 4096)  # Concatenate the outputs from all patches\n",
    "        self.fc3 = nn.Linear(4096, num_outputs)  # Output layer (can serve as self.output)\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        batch_size, num_patches, channels, height, width = input_batch.size()\n",
    "        \n",
    "        final_feat_vectors = None\n",
    "        \n",
    "        for patch_ind in range(self.siamese_deg):\n",
    "            # Each patch_batch would be of shape (batch_size, color_channels, h_patch, w_patch)\n",
    "            patch_batch = input_batch[:, patch_ind, :, :, :]\n",
    "            patch_batch_features = self.patch_model(patch_batch)\n",
    "\n",
    "            if patch_ind == 0:\n",
    "                final_feat_vectors = patch_batch_features\n",
    "            else:\n",
    "                final_feat_vectors = torch.cat([final_feat_vectors, patch_batch_features], dim=1)\n",
    "        \n",
    "        # Use fc3 as the output layer\n",
    "        x = self.fc2(final_feat_vectors)\n",
    "        x = F.log_softmax(self.fc3(x))\n",
    "        # x = F.log_softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# Initialize your self-supervised model\n",
    "self_supervised_model = SelfSupervisedModel(siamese_deg=9,num_outputs=1000)  # Replace 'siamese_deg' with the actual value\n",
    "\n",
    "print(self_supervised_model)\n",
    "\n",
    "# Calculate the number of parameters\n",
    "total_params = count_parameters(self_supervised_model)\n",
    "print(f\"Total model parameters: {total_params//1000000}M\")\n",
    "\n",
    "# Print the model architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jigsaw as pretext task training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders done\n",
      "torch.Size([32, 9, 3, 32, 32])\n",
      "torch.Size([32])\n",
      "Model ready\n",
      "Started training\n",
      "Epoch no 0 #######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_752883/3415212997.py:58: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.fc3(x))\n",
      "/tmp/ipykernel_752883/2667770443.py:147: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True).to(self.device), Variable(target).to(self.device)\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After epoch 0 - Test set: Average loss: 6.9082, Accuracy: 5/5000 (0%)\n",
      "\n",
      "\n",
      "After epoch 0 - Train set: Average loss: 6.9082, Accuracy: 41/45000 (0%)\n",
      "\n",
      "Train loss 6.908240557564177 \n",
      " Val loss 6.90821961593628 \n",
      " Train Acc 0.0009111111111111111 \n",
      " Val Acc 0.001\n",
      "Epoch no 1 #######################\n",
      "\n",
      "After epoch 1 - Test set: Average loss: 6.9091, Accuracy: 4/5000 (0%)\n",
      "\n",
      "\n",
      "After epoch 1 - Train set: Average loss: 6.9082, Accuracy: 52/45000 (0%)\n",
      "\n",
      "Train loss 6.908184941135236 \n",
      " Val loss 6.90910323638916 \n",
      " Train Acc 0.0011555555555555555 \n",
      " Val Acc 0.0008\n",
      "Epoch no 2 #######################\n",
      "\n",
      "After epoch 2 - Test set: Average loss: 6.8411, Accuracy: 23/5000 (0%)\n",
      "\n",
      "\n",
      "After epoch 2 - Train set: Average loss: 6.8962, Accuracy: 67/45000 (0%)\n",
      "\n",
      "Train loss 6.8961575761617455 \n",
      " Val loss 6.841146598815918 \n",
      " Train Acc 0.001488888888888889 \n",
      " Val Acc 0.0046\n",
      "Epoch no 3 #######################\n",
      "\n",
      "After epoch 3 - Test set: Average loss: 6.3906, Accuracy: 85/5000 (2%)\n",
      "\n",
      "\n",
      "After epoch 3 - Train set: Average loss: 6.6611, Accuracy: 534/45000 (1%)\n",
      "\n",
      "Train loss 6.661059397539519 \n",
      " Val loss 6.390583451843262 \n",
      " Train Acc 0.011866666666666666 \n",
      " Val Acc 0.017\n",
      "Epoch no 4 #######################\n",
      "\n",
      "After epoch 4 - Test set: Average loss: 5.4868, Accuracy: 295/5000 (6%)\n",
      "\n",
      "\n",
      "After epoch 4 - Train set: Average loss: 5.9677, Accuracy: 1571/45000 (3%)\n",
      "\n",
      "Train loss 5.967652977656708 \n",
      " Val loss 5.486832025146485 \n",
      " Train Acc 0.03491111111111111 \n",
      " Val Acc 0.059\n",
      "Epoch no 5 #######################\n",
      "\n",
      "After epoch 5 - Test set: Average loss: 2.0211, Accuracy: 2651/5000 (53%)\n",
      "\n",
      "\n",
      "After epoch 5 - Train set: Average loss: 3.6687, Accuracy: 12529/45000 (28%)\n",
      "\n",
      "Train loss 3.668681229186041 \n",
      " Val loss 2.0210899211883544 \n",
      " Train Acc 0.27842222222222224 \n",
      " Val Acc 0.5302\n",
      "Epoch no 6 #######################\n",
      "\n",
      "After epoch 6 - Test set: Average loss: 1.3499, Accuracy: 3382/5000 (68%)\n",
      "\n",
      "\n",
      "After epoch 6 - Train set: Average loss: 1.4730, Accuracy: 28831/45000 (64%)\n",
      "\n",
      "Train loss 1.4729959015187086 \n",
      " Val loss 1.3498974407196045 \n",
      " Train Acc 0.6406888888888889 \n",
      " Val Acc 0.6764\n",
      "Epoch no 7 #######################\n",
      "\n",
      "After epoch 7 - Test set: Average loss: 1.0026, Accuracy: 3717/5000 (74%)\n",
      "\n",
      "\n",
      "After epoch 7 - Train set: Average loss: 1.0470, Accuracy: 32920/45000 (73%)\n",
      "\n",
      "Train loss 1.0469924546592864 \n",
      " Val loss 1.0025706418037414 \n",
      " Train Acc 0.7315555555555555 \n",
      " Val Acc 0.7434\n",
      "Epoch no 8 #######################\n",
      "\n",
      "After epoch 8 - Test set: Average loss: 0.7236, Accuracy: 4068/5000 (81%)\n",
      "\n",
      "\n",
      "After epoch 8 - Train set: Average loss: 0.8515, Accuracy: 35023/45000 (78%)\n",
      "\n",
      "Train loss 0.8515230974959581 \n",
      " Val loss 0.7236343481063843 \n",
      " Train Acc 0.7782888888888889 \n",
      " Val Acc 0.8136\n",
      "Epoch no 9 #######################\n",
      "\n",
      "After epoch 9 - Test set: Average loss: 0.7168, Accuracy: 4049/5000 (81%)\n",
      "\n",
      "\n",
      "After epoch 9 - Train set: Average loss: 0.7153, Accuracy: 36464/45000 (81%)\n",
      "\n",
      "Train loss 0.715334672695284 \n",
      " Val loss 0.7167773855209351 \n",
      " Train Acc 0.8103111111111111 \n",
      " Val Acc 0.8098\n",
      "Epoch no 10 #######################\n",
      "\n",
      "After epoch 10 - Test set: Average loss: 0.5751, Accuracy: 4259/5000 (85%)\n",
      "\n",
      "\n",
      "After epoch 10 - Train set: Average loss: 0.6343, Accuracy: 37361/45000 (83%)\n",
      "\n",
      "Train loss 0.6342805825390965 \n",
      " Val loss 0.5750888862609863 \n",
      " Train Acc 0.8302444444444445 \n",
      " Val Acc 0.8518\n",
      "Epoch no 11 #######################\n",
      "\n",
      "After epoch 11 - Test set: Average loss: 0.4134, Accuracy: 4452/5000 (89%)\n",
      "\n",
      "\n",
      "After epoch 11 - Train set: Average loss: 0.4914, Accuracy: 39075/45000 (87%)\n",
      "\n",
      "Train loss 0.49136420163804534 \n",
      " Val loss 0.4134051914215088 \n",
      " Train Acc 0.8683333333333333 \n",
      " Val Acc 0.8904\n",
      "Epoch no 12 #######################\n",
      "\n",
      "After epoch 12 - Test set: Average loss: 0.3632, Accuracy: 4510/5000 (90%)\n",
      "\n",
      "\n",
      "After epoch 12 - Train set: Average loss: 0.3636, Accuracy: 40557/45000 (90%)\n",
      "\n",
      "Train loss 0.3635750068450915 \n",
      " Val loss 0.36318659341335296 \n",
      " Train Acc 0.9012666666666667 \n",
      " Val Acc 0.902\n",
      "Epoch no 13 #######################\n",
      "\n",
      "After epoch 13 - Test set: Average loss: 0.3603, Accuracy: 4529/5000 (91%)\n",
      "\n",
      "\n",
      "After epoch 13 - Train set: Average loss: 0.3079, Accuracy: 41257/45000 (92%)\n",
      "\n",
      "Train loss 0.30785697497633985 \n",
      " Val loss 0.36030991954803465 \n",
      " Train Acc 0.9168222222222222 \n",
      " Val Acc 0.9058\n",
      "Epoch no 14 #######################\n",
      "\n",
      "After epoch 14 - Test set: Average loss: 0.2390, Accuracy: 4678/5000 (94%)\n",
      "\n",
      "\n",
      "After epoch 14 - Train set: Average loss: 0.2794, Accuracy: 41636/45000 (93%)\n",
      "\n",
      "Train loss 0.2794034455054954 \n",
      " Val loss 0.2390493193745613 \n",
      " Train Acc 0.9252444444444444 \n",
      " Val Acc 0.9356\n"
     ]
    }
   ],
   "source": [
    "#for jigsaw ssl task\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    Cexperiment_name = 'our'\n",
    "    Cdataset_config = 'js_d2'\n",
    "    Cweight_decay = 5e-4\n",
    "    Clr = 1e-2\n",
    "    Cepochs = 15\n",
    "    Cbatch_size = 32\n",
    "\n",
    "    # Data files which will get referred\n",
    "    permuts_file_path = 'selected_permuts.npy'\n",
    "\n",
    "    # Set device to use to gpu if available and declare model_file_path\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #par_weights_dir = 'weights/'\n",
    "    model_file_path = 'resnet_jigsaw_solver_{}_trained.pt'.format(Cexperiment_name)\n",
    "\n",
    "    all_file_paths = get_paths()\n",
    "    # print(all_file_paths)\n",
    "    \n",
    "    # Get validation files separate\n",
    "    train_file_paths, val_file_paths = train_test_split(all_file_paths, test_size=0.1, shuffle=True, random_state=3)\n",
    "\n",
    "    # Compute channel means\n",
    "    channel_means = np.array([124.09, 127.67, 110.50]) / 256.0\n",
    "\n",
    "    # Define data transforms\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.RandomCrop((32, 32)),\n",
    "        transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Define data loaders\n",
    "    batch_size = Cbatch_size\n",
    "\n",
    "    if Cdataset_config == 'js_d1':\n",
    "        train_data_loader = DataLoader(\n",
    "            ConcatDataset(\n",
    "                [GetJigsawPuzzleDataset(train_file_paths, permuts_file_path,\n",
    "                                        range_permut_indices=[st_perm_ind, st_perm_ind+9], transform=data_transform)\n",
    "                 for st_perm_ind in range(0, 100, 10)\n",
    "                ]\n",
    "            ),\n",
    "            batch_size=batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "        val_data_loader = DataLoader(\n",
    "            ConcatDataset(\n",
    "                [GetJigsawPuzzleDataset(val_file_paths, permuts_file_path,\n",
    "                                        range_permut_indices=[st_perm_ind, st_perm_ind + 9], transform=data_transform)\n",
    "                 for st_perm_ind in range(0, 100, 10)\n",
    "                 ]\n",
    "            ),\n",
    "            batch_size=batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "    else:\n",
    "        train_data_loader = DataLoader(\n",
    "            GetJigsawPuzzleDataset(train_file_paths, permuts_file_path, transform=data_transform),\n",
    "            batch_size=batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "        val_data_loader = DataLoader(\n",
    "            GetJigsawPuzzleDataset(val_file_paths, permuts_file_path, transform=data_transform),\n",
    "            batch_size=batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "    print(\"Loaders done\")\n",
    "    # Print sample batches that would be returned by the train_data_loader\n",
    "    dataiter = iter(train_data_loader)\n",
    "    X, y = dataiter.__next__()\n",
    "    print (X.size())\n",
    "    print (y.size())\n",
    "\n",
    "    # Train required model defined above on CUB200 data\n",
    "    num_outputs = 1000#200\n",
    "    epochs = Cepochs\n",
    "    lr = Clr\n",
    "    weight_decay_const = Cweight_decay\n",
    "\n",
    "    # If using Resnet18\n",
    "    # model_to_train = resnet18(num_classes=num_outputs, siamese_deg=9)\n",
    "\n",
    "    model_to_train = SelfSupervisedModel(siamese_deg=9,num_outputs=1000)  # Replace 'siamese_deg' with the actual value\n",
    "\n",
    "    print('Model ready')\n",
    "    # Set device on which training is done. Plus optimizer to use.\n",
    "    model_to_train.to(device)\n",
    "    optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    # Start training\n",
    "    print('Started training')\n",
    "    model_train_test_obj = JigsawModelTrainTest(model_to_train, device, model_file_path)\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    for epoch_no in range(epochs):\n",
    "        print(\"Epoch no {} #######################\".format(epoch_no))\n",
    "        train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n",
    "            optimizer, epoch_no, params_max_norm=4,\n",
    "            train_data_loader = train_data_loader, val_data_loader = val_data_loader\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        print(\"Train loss {} \\n Val loss {} \\n Train Acc {} \\n Val Acc {}\".format(train_loss,val_loss,train_acc,val_acc))\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    observations_df = pd.DataFrame()\n",
    "    observations_df['epoch count'] = [i for i in range(1, Cepochs + 1)]\n",
    "    observations_df['train loss'] = train_losses\n",
    "    observations_df['val loss'] = val_losses\n",
    "    observations_df['train acc'] = train_accs\n",
    "    observations_df['val acc'] = val_accs\n",
    "    observations_file_path = Cexperiment_name + '_observations.csv'\n",
    "    observations_df.to_csv(observations_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('Loss plots')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "#plt.show()\n",
    "plt.savefig('loss.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_accs)\n",
    "plt.plot(val_accs)\n",
    "plt.title('Accuracy plots')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "#plt.show()\n",
    "plt.savefig('accuracy.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream classification training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train files list 4242\n",
      "Length of train labels list 4242\n",
      "Length of test files list 1414\n",
      "Length of test labels list 1414\n",
      "Length of train files list 3817\n",
      "Length of train labels 3817\n",
      "Length of val files list 425\n",
      "Length of val labels 425\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([1000, 18432]) from checkpoint, the shape in current model is torch.Size([10, 18432]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m     new_key \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mmodule.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Remove 'module.' prefix if it exists\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m     new_checkpoint[new_key] \u001b[39m=\u001b[39m value\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m model_to_train\u001b[39m.\u001b[39;49mload_state_dict(new_checkpoint)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m \u001b[39m# Load state dict for pre trained model weights\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m \u001b[39m# model_to_train.load_state_dict(torch.load(jigsaw_pre_trained_weights_path))\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=135'>136</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# Redefine the last linear layer\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.129.134.106/home/raj/GNR-650/Self-Supervised-Learning-for-Fine-grained-Image-Classification/Jigsaw_as_Pretext_task/Jigsaw_pretext_change.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m model_to_train\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m2048\u001b[39m, \u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([1000, 18432]) from checkpoint, the shape in current model is torch.Size([10, 18432]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "#for downstream classification\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms, utils, models\n",
    "torch.manual_seed(3)\n",
    "\n",
    "\n",
    "def visualize(sample_data_loader):\n",
    "\n",
    "    def imshow(img, mean=0.0, std=1.0):\n",
    "        \"\"\"\n",
    "        Parameters passed:\n",
    "        img: Image to display\n",
    "        mean: Mean that was subtracted while normalizing the images\n",
    "        std: Standard deviation that was used for division while normalizing the image\n",
    "        \"\"\"\n",
    "        img = img * std + mean  # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()\n",
    "\n",
    "    dataiter = iter(sample_data_loader)\n",
    "    images, labels = dataiter.__next__()\n",
    "    imshow(utils.make_grid(images))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "   \n",
    "    Cbatch_size = 32\n",
    "    Cepochs = 20\n",
    "    Coptim = 'adam'\n",
    "    Clr = 1e-4\n",
    "    Cweight_decay = 5e-4\n",
    "    Cjigsaw_task_weights = 'resnet_jigsaw_solver_e1_js_trained.pt'\n",
    "    Cmodel_file_name = 'resnet_trained_for_classification.pt'\n",
    "    Cexperiment_name = 'e1_last_b'\n",
    "    Ctrain_imagenet_based = False\n",
    "    Ctrain_ssl_block_4_ft = True\n",
    "    Ctrain_ssl_block_3_ft = False\n",
    "    Ctrain_ssl_full_ft = False\n",
    "    Ctrain_wo_ssl = False\n",
    "    \n",
    "    # Set device to use to gpu if available and declare model_file_path\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #par_weights_dir = 'weights/'\n",
    "    jigsaw_pre_trained_weights_path =  Cjigsaw_task_weights\n",
    "\n",
    "    # Data loading and data generators set up\n",
    "    train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = \\\n",
    "        get_train_test_file_paths_n_labels()\n",
    "\n",
    "    # Get validation files and validation labels separate\n",
    "    train_image_ids, val_image_ids, train_file_paths, val_file_paths, train_labels, val_labels = \\\n",
    "        split_train_into_train_val(train_image_ids, train_file_paths, train_labels, test_size=0.1)\n",
    "\n",
    "    # Compute channel means\n",
    "    channel_means = np.array([124.09, 127.67, 110.50]) / 256.0\n",
    "\n",
    "    # Define data loaders\n",
    "    batch_size = Cbatch_size\n",
    "    train_data_loader = DataLoader(\n",
    "        ConcatDataset(\n",
    "            [GetDataset(train_file_paths, train_labels, def_data_transform),\n",
    "             GetDataset(train_file_paths, train_labels, hflip_data_transform),\n",
    "             GetDataset(train_file_paths, train_labels, darkness_jitter_transform),\n",
    "             GetDataset(train_file_paths, train_labels, lightness_jitter_transform),\n",
    "             GetDataset(train_file_paths, train_labels, rotations_transform),\n",
    "             GetDataset(train_file_paths, train_labels, all_in_transform)]\n",
    "        ),\n",
    "        batch_size = batch_size, shuffle = True, num_workers = 8\n",
    "    )\n",
    "    val_data_gen = GetDataset(val_file_paths, val_labels, def_data_transform)\n",
    "    val_data_loader = DataLoader(\n",
    "        val_data_gen, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    )\n",
    "    test_data_gen = GetDataset(test_file_paths, test_labels, def_data_transform)\n",
    "    test_data_loader = DataLoader(\n",
    "        test_data_gen, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    )\n",
    "\n",
    "    # Visualize a batch of images\n",
    "    # visualize(train_data_loader)\n",
    "\n",
    "    # Train required model defined above on CUB200 data\n",
    "    num_classes = 5\n",
    "    epochs = Cepochs\n",
    "    lr = Clr\n",
    "    weight_decay_const = Cweight_decay\n",
    "\n",
    "    if Ctrain_imagenet_based:\n",
    "        model_to_train = models.resnet18(pretrained=True)\n",
    "        model_to_train.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "\n",
    "        model_to_train.fc = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 5),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "        model_file_path = 'resnet_imagenet_based.pt'\n",
    "\n",
    "    elif Ctrain_wo_ssl:\n",
    "        model_to_train = resnet18(num_classes=num_classes, siamese_deg=None)\n",
    "        model_file_path = 'resnet_trained_from_scratch.pt'\n",
    "\n",
    "    else:\n",
    "        model_to_train = resnet18(num_classes=num_classes, siamese_deg=None)\n",
    "        model_to_train.fc = nn.Linear(2048 * 9, 10)  # 2048 is the last resnet layer output length which gets\n",
    "        # multiplied with degree of siamese net, which for jigsaw puzzle solving was 9\n",
    "\n",
    "        checkpoint = torch.load(jigsaw_pre_trained_weights_path)\n",
    "        # print(checkpoint.keys())\n",
    "        \n",
    "        new_checkpoint = {}\n",
    "\n",
    "        # Iterate through the keys in the loaded checkpoint\n",
    "        for key, value in checkpoint.items():\n",
    "            # Modify the key to match the existing model's module name\n",
    "            new_key = key.replace('module.', '')  # Remove 'module.' prefix if it exists\n",
    "            new_checkpoint[new_key] = value\n",
    "\n",
    "        model_to_train.load_state_dict(new_checkpoint)\n",
    "\n",
    "        # Load state dict for pre trained model weights\n",
    "        # model_to_train.load_state_dict(torch.load(jigsaw_pre_trained_weights_path))\n",
    "\n",
    "        # Redefine the last linear layer\n",
    "        model_to_train.fc = nn.Linear(2048, 10)\n",
    "        \n",
    "        print('Model loaded successfully')\n",
    "\n",
    "        if Ctrain_ssl_block_4_ft:\n",
    "            model_file_path = 'resnet_trained_ssl_{}_last_a_ft.pt'.format(Cexperiment_name)\n",
    "            for name, param in model_to_train.named_parameters():\n",
    "                if name[:6] == 'layer4' or name in ['fc.0.weight', 'fc.0.bias']:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "        elif Ctrain_ssl_block_3_ft:\n",
    "            model_file_path = 'resnet_trained_ssl_{}_last_b_ft.pt'.format(Cexperiment_name)\n",
    "            for name, param in model_to_train.named_parameters():\n",
    "                if name[:6] == 'layer4' or name[:6] == 'layer3' or name in ['fc.0.weight', 'fc.0.bias']:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        else:\n",
    "            model_to_train.fc = nn.Linear(2048, 5)\n",
    "            model_file_path = 'resnet_trained_ssl_{}_full_ft.pt'.format(Cexperiment_name)\n",
    "\n",
    "\n",
    "    # Set device on which training is done. Plus optimizer to use.\n",
    "    model_to_train.to(device)\n",
    "    sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "    adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "    if Coptim == 'sgd':\n",
    "        optimizer = sgd_optimizer\n",
    "    else:\n",
    "        optimizer = adam_optimizer\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
    "\n",
    "    # Start training\n",
    "    model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    print('Training started')\n",
    "    for epoch_no in range(epochs):\n",
    "        train_loss, train_acc, val_loss, val_acc = model_train_test_obj.train(\n",
    "            optimizer, epoch_no, params_max_norm=4,\n",
    "            train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    observations_df = pd.DataFrame()\n",
    "    observations_df['epoch count'] = [i for i in range(1, Cepochs + 1)]\n",
    "    observations_df['train loss'] = train_losses\n",
    "    observations_df['val loss'] = val_losses\n",
    "    observations_df['train acc'] = train_accs\n",
    "    observations_df['val acc'] = val_accs\n",
    "    observations_file_path = Cexperiment_name + '_observations.csv'\n",
    "    observations_df.to_csv(observations_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('Loss plots')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "#plt.show()\n",
    "plt.savefig('e1_last_b_classification_loss.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_accs)\n",
    "plt.plot(val_accs)\n",
    "plt.title('Accuracy plots')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "#plt.show()\n",
    "plt.savefig('e1_last_b_classification_acc.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    pil_img = Image.open(path)\n",
    "    if pil_img.mode == \"L\":\n",
    "        return None\n",
    "    else:\n",
    "        return pil_img\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    Cmodel_name = 'resnet_trained_ssl_e1_last_b_last_b_ft.pt'\n",
    "    Ctest_compact_bilinear = True\n",
    "    Ctest_imagenet_based = False\n",
    "    Ctest_on = 'test'\n",
    "\n",
    "    # Set device to use to gpu if available and declare model_file_path\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #par_weights_dir = 'weights/'\n",
    "    model_file_path = Cmodel_name\n",
    "\n",
    "    # Data loading and data generators set up\n",
    "    train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = \\\n",
    "        get_train_test_file_paths_n_labels()\n",
    "\n",
    "    train_image_ids, val_image_ids, train_file_paths, val_file_paths, train_labels, val_labels = \\\n",
    "        split_train_into_train_val(train_image_ids, train_file_paths, train_labels, test_size=0.1)\n",
    "\n",
    "    if Ctest_imagenet_based:\n",
    "        model_to_train = models.resnet18(pretrained=True)\n",
    "        model_to_train.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        model_to_train.fc = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 5),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "    else:\n",
    "        model_to_train = resnet18(num_classes=5, siamese_deg=None)\n",
    "\n",
    "    # Check if saved model exists, and load if it does.\n",
    "    if os.path.exists(model_file_path):\n",
    "        model_to_train.load_state_dict(torch.load(model_file_path))\n",
    "    model_to_train.to(device)\n",
    "\n",
    "    # Setup on which set evaluation is to be carried out\n",
    "    if Ctest_on == 'train':\n",
    "        eval_file_paths, eval_labels = train_file_paths, train_labels\n",
    "    elif Ctest_on == 'val':\n",
    "        eval_file_paths, eval_labels = val_file_paths, val_labels\n",
    "    else:\n",
    "        eval_file_paths, eval_labels = test_file_paths, test_labels\n",
    "\n",
    "    # Start evaluation\n",
    "    model_to_train.eval()\n",
    "    correct = 0\n",
    "    preds = []\n",
    "    for f, label in zip(eval_file_paths, eval_labels):\n",
    "        pil_img = pil_loader(f)\n",
    "        if pil_img is None:\n",
    "            preds.append(0)\n",
    "            continue\n",
    "        data = def_data_transform(pil_img)\n",
    "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "        data = Variable(data, volatile=True).to(device)\n",
    "        output = model_to_train(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "        x = pred.data #prediction\n",
    "        preds.append(x)\n",
    "\n",
    "        if x == label:\n",
    "            correct += 1\n",
    "\n",
    "    print (correct, len(eval_file_paths), correct * 100 / len(eval_file_paths))\n",
    "    preds = np.array(preds).astype(np.float64)\n",
    "    conf_mat = np.array(confusion_matrix(preds, eval_labels))\n",
    "    conf_df = pd.DataFrame(conf_mat)\n",
    "    conf_df.columns = np.arange(0,5)\n",
    "    conf_df.to_csv('confusion_matrix.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
